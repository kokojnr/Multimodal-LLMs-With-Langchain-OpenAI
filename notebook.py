# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17WjaF0JiDkDRsu_qkrry-FfYscFpsv92

# Building Multimodal AI Applications with LangChain & the OpenAI API

##  Setup
"""

# Install the openai package, locked to version 1.27
!pip install openai==1.27

# Install the langchain package, locked to version 0.1.19
!pip install langchain==0.1.19

# Install the langchain-openai package, locked to version 0.1.6
!pip install langchain-openai==0.1.6

# Install the yt_dlp package, locked to version 2024.4.9
!pip install yt_dlp==2024.4.9

# Install the tiktoken package, locked to version 0.6.0
!pip install tiktoken==0.6.0

# Install the docarray package, locked to version 0.40.0
!pip install docarray==0.40.0

#install pydub package
!pip install pydub

"""## Import The Required Libraries"""

# Import the os package
import os

# Import the glob package
import glob

# Import the openai package
import openai

# Import the yt_dlp package as youtube_dl
import yt_dlp as youtube_dl

# Import DownloadError from yt_dlp
from yt_dlp import DownloadError

# Import DocArray
import docarray

# Import AudioSegment
from pydub import AudioSegment

openai_api_key = os.getenv("OPENAI_API_KEY")

"""## Download the Video"""

# Target video URL
video_url = "https://archive.org/details/0769_So_Youre_Going_to_High_School_18_16_46_00"

# Output directory
output_dir = "files/audio/"
os.makedirs(output_dir, exist_ok=True)

# yt-dlp config for MP3 extraction
ydl_opts = {
    "format": "bestaudio/best",
    "postprocessors": [
        {
            "key": "FFmpegExtractAudio",
            "preferredcodec": "mp3",
            "preferredquality": "192",
        }
    ],
    "outtmpl": os.path.join(output_dir, "%(title)s.%(ext)s"),
    "quiet": False,  # Show progress
    "noplaylist": True,
    "force_generic_extractor": True,  # <-- Add this line to force generic extractor
}

# Run downloader
try:
    with youtube_dl.YoutubeDL(ydl_opts) as ydl:
        ydl.download([video_url])
except:
    with youtube_dl.YoutubeDL(ydl_opts) as ydl:
        ydl.download([video_url])

print("Audio extraction complete!")

"""Find the audio file in the output directory.

- Find all the MP3 audio files in the output directory by joining the output directory to the pattern `*.mp3` and using glob to list them.
- Select the last file in the list and assign it to `audio_filename`.
-  Print `audio_filename`.
"""

# Find the audio file in the output directory

# Find all the audio files in the output directory
audio_file = glob.glob(os.path.join(output_dir, '*.mp3'))

# Select the last audio file in the list
audio_filename = audio_file[-1]

# Print the name of the selected audio file
print(audio_filename)

"""##  Transcribe the Video using GPT-4o-Mini-Transcribe"""

# Define variables
audio_file = audio_filename  # Make sure this variable exists (e.g. "files/audio/myfile.mp3")
output_file = "files/transcripts/text.txt"
model = "gpt-4o-mini-transcribe"

# Initialize OpenAI client
client = openai.OpenAI()  # stored API key in environment variable

# Ensure transcript output directory exists
output_dir = os.path.dirname(output_file)
if not os.path.exists(output_dir):
    os.makedirs(output_dir)
    print(f"Created directory: {output_dir}")

# Check if the audio file actually exists
if not os.path.exists(audio_file):
    raise FileNotFoundError(f"Audio file not found: {audio_file}")

# Check file size before sending to API
max_size_bytes = 25 * 1024 * 1024  # 25 MB
file_size = os.path.getsize(audio_file)

if file_size > max_size_bytes:
    print(
        f"Audio file is too large ({file_size} bytes). "
        f"Maximum allowed size is {max_size_bytes} bytes (25 MB)."
    )
    # Automatically trim the audio to fit the size limit
    print("Trimming audio to fit the size limit...")
    audio = AudioSegment.from_file(audio_file)
    duration_ms = len(audio)
    bytes_per_ms = file_size / duration_ms
    max_duration_ms = int(max_size_bytes / bytes_per_ms)
    trimmed_audio = audio[:max_duration_ms]
    trimmed_audio_file = "temp_trimmed_audio.mp3"
    trimmed_audio.export(trimmed_audio_file, format="mp3")
    audio_file = trimmed_audio_file
    print(f"Trimmed audio saved as {audio_file}")
else:
    print("Audio file size is within the allowed limit.")

print("\n Converting audio to text...")

# Transcribe
with open(audio_file, "rb") as audio:
    response = client.audio.transcriptions.create(
        model=model,
        file=audio
    )

# Extract and print transcript
transcript = response.text
print("\nTRANSCRIPT:\n")
print(transcript)

""" Save the transcript to a text file.

"""

# Create the directory for the output file if it doesn't exist
if output_file is None:
    os.makedirs(os.path.dirname(output_file, exist_ok=True))

# Write the transcript to the output file
    with open(output_file, 'w') as file:
        file.write(transcript)

"""## Create a TextLoader using LangChain"""

# From the langchain.document_loaders module, import TextLoader
from langchain.document_loaders import TextLoader

# Create a `TextLoader`, passing the directory of the transcripts. Assign to `loader`.
loader = TextLoader('./files/transcripts/text.txt')

# Use the TextLoader to load the documents. Assign to docs.

docs = loader.load()

# Show the first element of docs to verify it has been loaded
docs[0]

"""## Create an In-Memory Vector Store"""

# Import the tiktoken package
import tiktoken

"""## Create the Document Search"""

# Import the RetrievalQA class from the langchain.chains module
from langchain.chains import RetrievalQA

# Import the ChatOpenAI class from the langchain.chat_models module
from langchain.chat_models import ChatOpenAI

# Import the DocArrayInMemorySearch class from the langchain.vectorstores module
from langchain.vectorstores import DocArrayInMemorySearch

# Import the OpenAIEmbeddings class from the langchain.embeddings module
from langchain.embeddings import OpenAIEmbeddings

"""Create a vector store that will use the `DocArrayInMemory` search methods which will search through the created embeddings created by the OpenAI Embeddings function."""

# Create a new DocArrayInMemorySearch instance from the specified documents and embeddings
db = DocArrayInMemorySearch.from_documents(
    docs,
    OpenAIEmbeddings()
)

"""Create a retriever from the `db`. This enables the retrieval of the stored embeddings. Using the `ChatOpenAI` model as our LLM.


"""

# Convert the DocArrayInMemorySearch instance to a retriever
retriever = db.as_retriever()

# Create a new ChatOpenAI instance with a temperature of 0.0
llm = ChatOpenAI(temperature=0.0)

"""Create the `RetrievalQA` chain. This chain takes in the:  
- The `llm` we want to use.
- The `chain_type` which is how the model retrieves the data. Here we will use a _stuff_ chain, where all the documents are stuffed into the prompt. It is the simplest type, but only works where you only have a few small documents.
- The `retriever` that we have created.
- An option called `verbose` that prints details of each step of the chain.
"""

# Create a new RetrievalQA instance with the specified parameters
qa_stuff = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type='stuff',
    retriever=retriever,
    verbose=True
)

"""## Create the Queries"""

# Set the query to be used for the QA system
query = "what is the topic of discussion"

# Invoke the query through the RetrievalQA instance. Assign to response.
response = qa_stuff.run(query)

# Print the response to the console
print(response)

# Set the query to be used for the QA system
query = "how can students make informed decision about their future"

# Invoke the query through the RetrievalQA instance and store the response
response = qa_stuff.run(query)

# Print the response to the console
print(response)

# Set the query to be used for the QA system
query = "Who should watch this lesson?"

# Invoke the query through the RetrievalQA instance and store the response
response = qa_stuff.run(query)

# Print the response
print(response)

"""Continue creating queries and even creating queries that we know would not be answered in this video to see how the model responds."""

# Set the query to be used for the QA system
query = "Who is the greatest football team on earth?"

# Invoke the query through the RetrievalQA instance and store the response
response = qa_stuff.run(query)

# Print the response to the console
print(response)

# Set the query to be used for the QA system
query = "How long is the circumference of the earth?"

# Invoke the query through the RetrievalQA instance and store the response
response = qa_stuff.run(query)

# Print the response to the console
print(response)